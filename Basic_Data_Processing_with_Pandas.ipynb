{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "-----\n",
    " - Where to get help from? Stack Overflow!\n",
    " - Reference books: Python for Data Analyst by O'reilly, Learning the Pandas Library by Matt Harrison\n",
    " - Planet Python: https://planetpython.org/\n",
    " - Data Skeptic podcast: https://dataskeptic.com/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Series Data Structure\n",
    "\n",
    "-------\n",
    " - The series is one of the core data structures in pandas. You think of it across between a list and a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series? # you can see the documentation, you can pass in some data, an index, and a name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Underneath panda stores series values in a typed array using the Numpy library. This offers significant speed-up when processing data versus traditional python lists. \n",
    " - Underneath, pandas does some type conversion. If we create a list of strings and we have one element, a None type, pandas inserts it as a None and uses the type object for the underlying array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', None]\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - NAN is not none and when we try the equality test, it's false. \n",
    " - You need to use special functions to test for the presence of not a number, such as the Numpy library `isnan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, None]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - A series can be created from dictionary data. If you do this, the index is automatically assigned to the keys of the dictionary that you provided and not just incrementing integers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Once the series has been created, we can get the index object using the index attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - You could also separate your index creation from the data by passing in the index as a list explicitly to the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['Tiger', 'Bear', 'Moose'], index = ['India', 'America', 'Canada'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Pandas overrides the automatic creation to favor only and all of the indices values that you provided. So it will ignore it from your dictionary, all keys, which are not in your index, and pandas will add non type or NAN values for any index value you provide, which is not in your dictionary key list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports, index=['Golf', 'Sumo', 'Hockey'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quering a Series\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - To query by numeric location, starting at zero, use the `iloc` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - To query by the index label, you can use the `loc` attribute.\n",
    " - Keep in mind that `iloc` and `loc` are not methods, they are attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Golf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - So what happens if your index is a list of integers? This is a bit complicated, and Pandas can't determine automatically whether you're intending to query by index position or index label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports = {99: 'Bhutan',\n",
    "         100: 'Scotland',\n",
    "         101: 'Japan',\n",
    "         102: 'South Korea'}\n",
    "s = pd.Series(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0] # This won't call s.iloc[0] as one might expect, it generates an error instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Let's talk about working with the data. A common task is to want to consider all of the values inside of a series and want to do some sort of operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([100.00, 120.00, 101.00, 3.00])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We could write a little routine which iterates over all of the items in the series and adds them together to get a total. This works, but it's slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for item in s:\n",
    "    total += item\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Pandas and the underlying NumPy libraries support a method of computation called vectorization. \n",
    " - we just call `np.sum` and pass in an iterable item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "total = np.sum(s)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `head` method reduces the amount of data printed out by the series to the first five elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creats a big series of random numbers\n",
    "s = pd.Series(np.random.randint(0,1000,10000))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `timeit`\n",
    "- let's see if the second solution is actually faster than the other one? we can examin this with a magic function! :D\n",
    "- Magic functions begin with a % sign. If we type this sign and then hit the Tab key, we can see a list of the available magic functions. \n",
    "- We're actually going to use what's called a cellular magic function. These start with two percentage signs.`%%timeit`\n",
    "- You can give timeit the number of loops that you would like to run. By default, we'll use 1,000 loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = 0\n",
    "for item in s:\n",
    "    summary += item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "summary = np.sum(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Related feature in Pandas and NumPy is called broadcasting. With broadcasting, you can apply an operation to every value in the series, changing the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s += 2 #adds two to each item in s using broadcasting\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label, value in s.iteritems():\n",
    "    s.at[label] = value + 2\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0, 1000, 10000))\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label] = value + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "s = pd.Series(np.random.randint(0, 1000, 10000))\n",
    "s += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The .loc attribute lets you not only modify data in place, but also add new data as well. If the value you pass in as the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types.\n",
    " - While it's important to be aware of the typing going on underneath, Pandas will automatically change the underlying NumPy types as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s.loc['Animal'] = 'Bears'\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - There are a couple of important considerations when using append:\n",
    "     1. Pandas is going to take your series and try to infer the best data types to use. \n",
    "     2. the append method doesn't actually change the underlying series. It instead returns a new series which is made up of the two appended together. \n",
    "     (This is actually a significant issue for new Pandas users who are used to objects being changed in place. So watch out for it, not just with append but with other Pandas functions as well.)\n",
    "     3. we see that when we query the appended series for those who have cricket as their national sport, we don't get a single value, but a series itself. This is actually very common, and if you have a relational database background, this is very similar to every table query resulting in a return set which itself is a table. \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sports = pd.Series({'Archery': 'Bhutan',\n",
    "                            'Golf': 'Scotland',\n",
    "                            'Sumo': 'Japan',\n",
    "                            'Taekwando': 'South Korea'})\n",
    "cricket_loving_countries = pd.Series(['Autralia',\n",
    "                                     'Barbados',\n",
    "                                     'Pakistan',\n",
    "                                     'England'],\n",
    "                                    index=['Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket',\n",
    "                                          'Cricket'])\n",
    "all_countries = original_sports.append(cricket_loving_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_loving_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The DataFrame Data Structure\n",
    "-------\n",
    " - The DataFrame data structure is the heart of the Panda's library. It's a primary object that you'll be working with in data analysis and cleaning tasks. \n",
    " - The DataFrame is conceptually a two-dimensional series object, where there's an index and multiple columns of content, with each column having a label. \n",
    " - In fact, the distinction between a column and a row is really only a conceptual distinction. And you can think of the DataFrame itself as simply a two-axes labeled array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "purchase_1 = pd.Series({'Name': 'Chris',\n",
    "                       'Item Purchased': 'Dog Food',\n",
    "                       'Cost': 22.50})\n",
    "purchase_2 = pd.Series({'Name': 'Kevin',\n",
    "                       'Item Purchased': 'Kitty Litter',\n",
    "                       'Cost': 2.50})\n",
    "purchase_3 = pd.Series({'Name': 'Vinod',\n",
    "                       'Item Purchased': 'Bird Seed',\n",
    "                       'Cost': 5.00})\n",
    "df = pd.DataFrame([purchase_1, purchase_2, purchase_3], index = ['Store 1', 'Store 1', 'Store 2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Because the DataFrame is two-dimensional, passing a single value to the `loc` indexing operator will return series if there's only one row to return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['Store 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It's important to remember that the indices and column names along either axes, horizontal or vertical, could be non-unique. \n",
    " - For instance, in this example, we see two purchase records for Store 1 as different rows. If we use a single value with the DataFrame `loc` attribute, multiple rows of the DataFrame will return, not as a new series, but as a new DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - One of the powers of the Panda's DataFrame is that you can quickly select data based on multiple axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1', 'Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What if we just wanted to do column selection and just get a list of all of the costs? \n",
    "     1. First, you can get a transpose of the DataFrame, using the capital T attribute, which swaps all of the columns and rows. This essentially turns your column names into indices. And we can then use the `loc` method. This works, but it's pretty ugly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.loc['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Since iloc and loc are used for row selection, the Panda's developers reserved indexing operator directly on the DataFrame for column selection. \n",
    " - In a Panda's DataFrame, columns always have a name. So this selection is always label based\n",
    "     2. So the second way to do it is by simply using indexing operator:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - You can also chain operations together.\n",
    " - Chaining can come with some costs and is best avoided if you can use another approach. In particular, chaining tends to cause Pandas to return a copy of the DataFrame instead of a view on the DataFrame. \n",
    " - For selecting a data, this is not a big deal, though it might be slower than necessary. If you are changing data though, this is an important distinction and can be a source of error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Store 1']['Cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `.loc` also supports slicing. If we wanted to select all rows, we can use a column to indicate a full slice from beginning to end. And then add the column name as the second parameter as a string. In fact, if we wanted to include multiply columns, we could do so in a list. And Pandas will bring back only the columns we have asked for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['Name', 'Cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It's easy to delete data in series and DataFrames, and we can use the `drop` function to do so. \n",
    " - This function takes a single parameter, which is the index or roll label, to drop. \n",
    " - The drop function doesn't change the DataFrame by default. And instead, returns to you a copy of the DataFrame with the given rows removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Store 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Let's make a copy with the copy method and do a drop on it instead. This is a very typical pattern in Pandas, where in place changes to a DataFrame are only done if need be, usually on changes involving indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df.copy()\n",
    "copy_df = copy_df.drop('Store 1')\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Drop has two interesting optional parameters. The first is called in place, and if it's set to true, the DataFrame will be updated in place, instead of a copy being returned. \n",
    " - The second parameter is the axes, which should be dropped. By default, this value is 0, indicating the row axes. But you could change it to 1 if you want to drop a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del copy_df['Name']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Indexing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = df['Cost']\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs += 2\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat olympics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('olympics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('olympics.csv', index_col = 0, skiprows = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col[:2] == '01':\n",
    "        df.rename(columns = {col:'Gold' + col[4:]}, inplace = True)\n",
    "    if col[:2] == '02':\n",
    "        df.rename(columns = {col:'Silver' + col[4:]}, inplace = True)\n",
    "    if col[:2] == '03':\n",
    "        df.rename(columns = {col:'Bronze' + col[4:]}, inplace = True)\n",
    "    if col[:1] == '№':\n",
    "        df.rename(columns = {col:'#' + col[1:]}, inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quering a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gold'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = df.where(df['Gold'] > 0)\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold['Gold'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gold'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = only_gold.dropna()\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_gold = df[df['Gold'] > 0]\n",
    "only_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df['Gold'] > 0) | (df['Gold.1'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Gold.1'] > 0) & (df['Gold'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = df.index\n",
    "df = df.set_index('Gold')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('census.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SUMLEV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['SUMLEV'] == 50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['STNAME',\n",
    "                  'CTYNAME',\n",
    "                  'BIRTHS2010',\n",
    "                  'BIRTHS2011',\n",
    "                  'BIRTHS2012',\n",
    "                  'BIRTHS2013',\n",
    "                  'BIRTHS2014',\n",
    "                  'BIRTHS2015',\n",
    "                  'POPESTIMATE2010',\n",
    "                  'POPESTIMATE2011',\n",
    "                  'POPESTIMATE2012',\n",
    "                  'POPESTIMATE2013',\n",
    "                  'POPESTIMATE2014',\n",
    "                  'POPESTIMATE2015']\n",
    "df = df[columns_to_keep]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['STNAME', 'CTYNAME'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Michigan', 'Washtenaw County']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[('Michigan', 'Washtenaw County'),\n",
    "        ('Michigan', 'Wayne County')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('log.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('time')\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.set_index(['time', 'user'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
